{
  
    
        "post0": {
            "title": "A basic Learner",
            "content": "!pip install -Uqq fastbook import fastbook fastbook.setup_book() . |████████████████████████████████| 727kB 10.8MB/s |████████████████████████████████| 51kB 5.0MB/s |████████████████████████████████| 194kB 28.1MB/s |████████████████████████████████| 1.2MB 16.2MB/s |████████████████████████████████| 61kB 5.0MB/s |████████████████████████████████| 51kB 3.8MB/s Mounted at /content/gdrive . from fastai.vision.all import * from fastbook import * import pandas as pd . path = untar_data(URLs.MNIST_SAMPLE) path.ls() . (#3) [Path(&#39;/root/.fastai/data/mnist_sample/valid&#39;),Path(&#39;/root/.fastai/data/mnist_sample/labels.csv&#39;),Path(&#39;/root/.fastai/data/mnist_sample/train&#39;)] . labels_df = pd.read_csv(path/&quot;labels.csv&quot;) labels_df.head(3) . name label . 0 train/3/7463.png | 0 | . 1 train/3/21102.png | 0 | . 2 train/3/31559.png | 0 | . path.ls()[0].ls() . (#2) [Path(&#39;/root/.fastai/data/mnist_sample/valid/7&#39;),Path(&#39;/root/.fastai/data/mnist_sample/valid/3&#39;)] . def load_img(img_path): img = Image.open(path/img_path) img = tensor(img).view(28*28).float()/255 return img train_df = labels_df.loc[labels_df[&#39;name&#39;].str.contains(&#39;train&#39;), :] test_df = labels_df.loc[labels_df[&#39;name&#39;].str.contains(&#39;valid&#39;), :] train_dst = [(load_img(row[&#39;name&#39;]), tensor(row[&#39;label&#39;])) for _, row in train_df.iterrows()] test_dst = [(load_img(row[&#39;name&#39;]), tensor(row[&#39;label&#39;])) for _, row in test_df.iterrows()] . train_dst[0][0].shape, train_dst[0][1].shape, test_dst[0][0].shape, test_dst[0][1].shape . (torch.Size([784]), torch.Size([]), torch.Size([784]), torch.Size([])) . class BasicLearner: __name__ = &#39;BasicLearner&#39; __repr__ = basic_repr(&#39;dls,model,opt_func,loss_func,metrics&#39;) def __init__(self, dls, model, opt_func, loss_func, metrics): store_attr(&#39;dls,model,opt_func,loss_func,metrics&#39;) def fit(self, epochs=10, lr=1e-2): opt = self.opt_func(self.model.parameters(), lr=lr) for e in range(epochs): self.model.train() train_loss = [] for x,y in self.dls.train: pred = self.model(x) # print(pred.shape, y.shape) loss = self.loss_func(pred, y) train_loss.append(loss) opt.zero_grad() loss.backward() opt.step() train_loss = tensor(train_loss) self.model.eval() val_loss = [] val_metrics = [] for x,y in self.dls.valid: pred = self.model(x) loss = self.loss_func(pred, y) val_loss.append(loss) m = self.metrics(pred, y) val_metrics.append(m) val_loss = tensor(val_loss) val_metrics = tensor(val_metrics) msg = f&quot;Epoch {e}/{epochs}: &quot; f&quot;Train loss {train_loss.mean():.4f} &quot; f&quot;Valid loss {val_loss.mean():.4f} &quot; f&quot;{self.metrics.__name__} {val_metrics.mean():.2f}&quot; print(msg) . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() def batch_accuracy(predictions, targets): predictions = predictions.sigmoid() correct = (predictions &gt; 0.5) == targets return correct.float().mean() . class BasicOptim: __name__ = &quot;BasicOptim&quot; __repr__ = basic_repr(&#39;parameters,lr&#39;) def __init__(self, parameters, lr): self.parameters, self.lr = list(parameters), lr def step(self, *args, **kwargs): for p in self.parameters: p.data -= p.grad * self.lr def zero_grad(self, *args, **kwargs): for p in self.parameters: p.grad = None . bs = 128 train_dl = DataLoader(train_dst, batch_size=bs) test_dl = DataLoader(test_dst, batch_size=bs, shuffle=False) dls = DataLoaders(train_dl, test_dl) . simple_net = nn.Sequential( nn.Linear(28*28, 30), nn.ReLU(), nn.Linear(30, 1), ) . . learn = BasicLearner(dls, simple_net, BasicOptim, mnist_loss, batch_accuracy) print(learn) . BasicLearner(dls=&lt;fastai.data.core.DataLoaders object at 0x7fb68a127c50&gt;, model=Sequential( (0): Linear(in_features=784, out_features=30, bias=True) (1): ReLU() (2): Linear(in_features=30, out_features=1, bias=True) ), opt_func=&lt;class &#39;__main__.BasicOptim&#39;&gt;, loss_func=&lt;function mnist_loss at 0x7fb68a07a5f0&gt;, metrics=&lt;function batch_accuracy at 0x7fb68a07a170&gt;) . . learn.fit(10) . Epoch 0/10: Train loss 0.0530 Valid loss 0.0643 batch_accuracy 0.95 Epoch 1/10: Train loss 0.0503 Valid loss 0.0617 batch_accuracy 0.96 Epoch 2/10: Train loss 0.0480 Valid loss 0.0596 batch_accuracy 0.96 Epoch 3/10: Train loss 0.0460 Valid loss 0.0578 batch_accuracy 0.96 Epoch 4/10: Train loss 0.0444 Valid loss 0.0563 batch_accuracy 0.96 Epoch 5/10: Train loss 0.0429 Valid loss 0.0550 batch_accuracy 0.96 Epoch 6/10: Train loss 0.0416 Valid loss 0.0538 batch_accuracy 0.96 Epoch 7/10: Train loss 0.0404 Valid loss 0.0528 batch_accuracy 0.96 Epoch 8/10: Train loss 0.0394 Valid loss 0.0519 batch_accuracy 0.96 Epoch 9/10: Train loss 0.0384 Valid loss 0.0510 batch_accuracy 0.96 .",
            "url": "https://andreeas26.github.io/my-notes/fastpages/jupyter/learner/2021/03/02/basic-learner.html",
            "relUrl": "/fastpages/jupyter/learner/2021/03/02/basic-learner.html",
            "date": " • Mar 2, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://andreeas26.github.io/my-notes/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://andreeas26.github.io/my-notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://andreeas26.github.io/my-notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}